# Download metadata option
# Download and save metadata in scripts
 in metadata.  Include note that to get most recent data, set usedatacache=false.  Add return=metadata&format={ascii,bibtex}.  Include note if .cite file not found.
# Save data in scripts
# Include request ID in scripts and metatada.  Turn ID into query string with server request.
# Include granule list and access times
# Add note that usedatacache=false for fast response time and provide info on access time of data.
# Create full Weygand catalog
# Demo when catalog is selected, create links in catalog info block for downloading Autoplot bookmarks.

# Better tooltips on dropdowns.  Same for ViViz.
# ViViz option to set size - window size will be ignored.
# Provide link to search through TSDS logs for catalog=PATTERN.  Provide download=log=format={TSDS requests, TSDS granule requests where no server hit was involved} option.
# Output SPASE option
# Hover over Autoplot image in Gallery gives option of opening Autoplot, downloading PDF/SVG.  Think about going over to thin client mode.

http://tsds.net/get/?catalog=SSCWeb&dataset=ace&return=log

http://tsds.net/get/?catalog=SSCWeb&dataset=ace&return=autoplot-bookmarks

http://tsds.net/get/?catalog=SSCWeb&dataset=ace&return=tsds

http://localhost:8004/?catalog=IMAGE/PT1M&dataset=ABK&parameters=X&start=-P3D&stop=2014-09-30&return=urilistflat

http://localhost:8004/?catalog=IMAGE/PT1M&dataset=ABK&parameters=X&start=-P3D&stop=2014-09-30&return=urilistflat (TODO: Need to add access times and last known MD5 and file size.)

--

= Definitions =

* TSDS - Time Series Data Server - A "back-end" data server.  Handles concatenation of granules (both files in directories and requests from data servers).  Uses Autoplot file processor libraries and custom code written in node.js.  Handles things like optimizing delivery speed of data and minimizing duplicate or redunant requests to servers it pulls data from.
* TSDSFE - Takes an input of catalog, dataset, timerange and allows visualization in Autoplot and ViViz and creates ~10 line "fill my array scripts" in IDL/Python/MATLAB. Also monitors back-end servers that it needs and reports on problems.
* TSDS Catalog - Contains information needed by TSDSFE to do everything (uses URI Templates)
* DD - [http://tsds.org/dd Data Description] Used for communication between Autoplot and ViViz.  Also used as an simple way of creating a TSDS Catalog with a URL string.

= Overview of Demo =

Use the Weygand Bow Shock Data Set to show process of 
* Using a DD to create a catalog to enable all of the value-added services that TSDSFE connects to.
* Show how to build a proper TSDSFE Catalog.

Major SPASE related issues encountered:
* SPASE records have incorrect start/stop times for datasets.
* Granules have timeformats and fill values that vary within dataset.  SPASE record does not indicate this. README found in granule directory indicates timeformat should be same for all granules in dataset.
* Directory naming convention for granules varies and is inconsistent with SPASE record.
* Lack of a pointer in dataset README to SPASE record and vice-versa.
* Variable naming convention in dataset README is different from that used in SPASE record.
* Fill values not documented in SPASE record but appear in README.

All of these issues are not surprising.  The the job of completing a SPASE record is considered complete if it passes schema validation tests.  Because no tests are not to validate other things that are needed by automated processing or for potential points of confusion by human consumers of the SPASE record.

I am not sure how many people prefer the README vs. the SPASE record.  Based on experience, I usually go directly to the README as I know that that the transformation of information in a README to that in the SPASE records can often be, say ..., quite

Preview of things we can do given a TSDFE Catalog for Weygand Bow Shock Data Set:
* Download a parameter and dataset into IDL/Python/MATLAB data structure; includes a README for information on how to cite.
* View overview plots of the entire dataset (one day per plot) [Time Series | Power Spectrum | Histogram]
* View and explort data for a given parameter in Autoplot
* View a web-based plot of a given parameter in a specified timerange [PDF|SVG|PNG]
* View a numbers used to generate plot of a given parameter in a [Web Page|ASCII File]
* Import a list of bookmarks for all datasets/parameters into Autoplot
* Create a link to a plot that can be sent to a colleague for comment
* Explore other things that TSDSFE can do with this dataset

= Steps =

== Preliminary ==

# [https://www.google.com/webhp?sourceid=chrome-instant&ion=1&espv=2&ie=UTF-8#q=weygand%20bow%20shock%20data%20set Search for weygand bow shock data set]
# [http://vmo.nasa.gov/mission/metadata/VMO/NumericalData/Weygand/Wind/TAP/Propagated.3DP/GSE/PT60S.xml Inspect first link]
# Find reference to 
: http://vmo.igpp.ucla.edu/data1/Weygand/PropagatedSolarWindGSE/weimer/Wind/TAP
# Inspect link above and find
: http://vmo.igpp.ucla.edu/data1/Weygand/PropagatedSolarWindGSE/weimer/Wind/TAP/V3/
# Note that V3 directory was not mentioned in SPASE record.  
# Look for Start/End time in SPASE record, and attempt to verify it is correct by inspection of [http://vmo.igpp.ucla.edu/data1/Weygand/PropagatedSolarWindGSE/weimer/Wind/TAP/V3/ data directory].  Find directory has data through 2014-09 but SPASE record has <code>End = 2010-06-30T23:59:00.000</code>. Decide to use directory End date. ''This is why I advocate the autogeneration and nightly updating of SPASE records for details like this.  At one point in time, the End date was correct.  But once the record is written, it requires human manual inspection to update it.  Which probably won't occur after the grant expires.''

I now have enough information to serve this data through TSDSFE.  I am going to do this using three approaches: 
# By telling TSDSFE the minimal amount of information it needs to serve the numbers from one of the datasets.
# By telling TSDSFE the minimal amount of information to allow it to create plots with appropriate labels and provide links to information about the data from one of the datasets.
# By writing a TSDSFE catalog with the full information about all of the data sets.

Then, I'll discuss how a hypothetical SPASE service could have been used to do 3 instead.

To do 1.-3., TSDS needs a TSDS catalog.  Within a catalog is a list of datasets.  

== 1. ==

Decide URI template is

http://vmo.igpp.ucla.edu/data1/Weygand/PropagatedSolarWindGSE/weimer/Wind/TAP/V3/$Y/windTAP$Y$m.dat

I could enter this in Autoplot and it would give me a GUI for selecting the columns that I want to plot and I could plot it over an arbitrary time range.  I would need to manually determine the column labels as the data files do not contain a header.

To do 1., I need to use this <code>dd</code> string:

 <nowiki>uri=http://vmo.igpp.ucla.edu/data1/Weygand/PropagatedSolarWindGSE/weimer/Wind/TAP/V3/$Y/windTAP$Y$m.dat&start=1995-01-01&stop=2014-09-01&timeFormat=$d $m $Y $H $M $S</nowiki>

I append this string to <nowiki>http://localhost:8004/#</nowiki> and enter the following into a browser

 http://localhost:8004/#uri=http://vmo.igpp.ucla.edu/data1/Weygand/PropagatedSolarWindGSE/weimer/Wind/TAP/V3/$Y/windTAP$Y$m.dat&start=1995-01-01&stop=2014-09-01&timeFormat=$d $m $Y $H $M $S

and then inpsect the GUI and use it to help form requests for data.  The GUI recognizes that there is only one data set and one parameter in the catalog, so it selected them automatically.  

When the above URL was entered in the browser, it sent the query string to the TSDS server, which created a TSDS catalog.  To view the catalog that was created and that the GUI is now working with, select the link named "Catalog configuration" near the bottom of the page in the Catalog section.  Note that the catalog created has one data set with id=<code>1</code> and one parameter with id=<code>1</code> (it assumed the first non-time column was the only parameter and gave it a name of "1").

This above dd is the minimal amount of information that I needed to start serving numbers (for non-ASCII files, a bit more additional information would be needed - more on that later).

Next I selected <code>ascii-0</code> verified that the first line returned 

 29 08 2014 00 00 00.000 4.121e+03

is found in the [http://vmo.igpp.ucla.edu/data1/Weygand/PropagatedSolarWindGSE/weimer/Wind/TAP/V3/2014/windTAP201408.dat source data file by searching for <code>29 08 2014 00 00 00.000</code> in the file.

== 2. ==

I used the SPASE record to find parameter names.  Parameter names <code>nxangle</code>, <code>nyangle</code>, <code>nzangle</code>, and <code>Propagation flag</code>, were taken from SPASE record <code>ParameterKey</code> element.

Next I append to the previous <code>dd</code> additional information:

 &dataColumns=7,8,9,10,11&dataIDs=nxangle,nyangle,nzangle,Propagation flag&catalogLabel=Weigand SW Propagation Data Set&datasetID=spase://VMO/NumericalData/Weygand/Wind/TAP/Propagated.3DP/GSE/PT60S

And append this to the URL used in 1.:

 http://localhost:8004/#uri=http://vmo.igpp.ucla.edu/data1/Weygand/PropagatedSolarWindGSE/weimer/Wind/TAP/V3/$Y/windTAP$Y$m.dat&start=1995-01-01&stop=2014-09-01&timeFormat=$d $m $Y $H $M $S&columns=7,8,9,10,11&columnIDs=nxangle,nyangle,nzangle,Propagation flag&catalogLabel=Weigand SW Propagation Data Set&datasetID=spase://VMO/NumericalData/Weygand/Wind/TAP/Propagated.3DP/GSE/PT60S&fillValues=1e34

and inpsect the GUI and use it to form requests for data.  Of course, this URL is getting a bit cumbersome and we have only described one dataset in the catalog with this method.  This method is useful for quick-checks of a single data set and follows the style used by Autoplot in adding modifiers to a URL in order to add additional information about the dataset.

== 3. ==

To do this, I clicked first on the catalog link on the bottom of the page and then opened it with a text editor.  I then inspected everything at http://vmo.igpp.ucla.edu/data1/Weygand/ and filled in the catalog.

The directory http://vmo.igpp.ucla.edu/data1/Weygand/ has subdirectories of

* ProcessedSolarWindGSE/
* ProcessedSolarWindGSM/
* PropagatedSolarWindGSE/
* PropagatedSolarWindGSM/

I have created the needed metadata for the last two.  ''NB: It would be very helpful if there was a README in these directories that pointed to the SPASE records.''

Directory structure
 PropagatedSolarWindGSM/
   parallel/
   	 ACE/
   	 Geotail/
   	 IMP8/
   	 ISEE1/
   	 ISEE2/
   	 ISEE3/
   	 Wind/
   weimer/
     Geotail/
     	mag/
     	 - header4dat
   		mag_cpi/
   		 - No header4dat file
   		plasma/
   		 - header4dat
   		plasma_cpi/
   		 - header4dat
     Wind/
     	mag/
     	 - header4dat
     	mag_swe/
     	 - No header4dat file
     	plasma/
     	 - header4dat
     	swe/
     	 - No header4dat file
     ace/
     imp8/
     isee1/
     isee2/

''Note the inconsistent use of capitialization for S/C names''.

Note the incosistent use of NaN vs. fill values across datasets.  Some use -1e34, others NaN.


The following code was used to generate the TSDSFE catalog.  The basic approach is to write a DD for each directory based on information in the header4dat files and then convert all of the DDs to a TSDSFE catalog node and combine them all together.  Below are the DDs that were used by code for weimer/Geotail/mag:

   weimer/
     Geotail/
     	mag/
     	 - header4dat
     	 - DD1: stop=2007-05-31T23:59:00.000Z&uri=http://vmo.igpp.ucla.edu/data1/Weygand/PropagatedSolarWindGSM/weimer/Geotail/mag/$Y/geotailmagP$Y$m.dat&timeFormat=$Y $m $d $H $M $S&catalogLabel=Weygand SW Propagation Data Set&datasetID=Weygand/PropagatedSolarWindGSM/weimer/Geotail/mag&columns=7,8,9,10,11,12&columnIDs=Bx GSM,By GSM,Bz GSM,x GSM,y GSM,z GSM&columnUnits=nT,nT,nT,Re,Re,Re&fillValues=NaN
     	 - DD2: start=2007-06-01&uri=http://vmo.igpp.ucla.edu/data1/Weygand/PropagatedSolarWindGSM/weimer/Geotail/mag/$Y/geotailmagP$Y$m.dat&timeFormat=$d $m $Y $H $M $S&catalogLabel=Weygand SW Propagation Data Set&datasetID=Weygand/PropagatedSolarWindGSM/weimer/Geotail/mag&columns=7,8,9,10,11,12&columnIDs=Bx GSM,By GSM,Bz GSM,x GSM,y GSM,z GSM&columnUnits=nT,nT,nT,Re,Re,Re&fillValues=NaN
   		mag_cpi/
   		 - No header4dat file
   		plasma/
   		 - header4dat
   		plasma_cpi/
   		 - header4dat

In attempting to use the DD2 above for the dataset <code>weimer/Geotail/mag</code> + existing code to determine the start and stop time of the dataset, I found that files through [http://vmo.igpp.ucla.edu/data1/Weygand/PropagatedSolarWindGSM/weimer/Geotail/mag/2007/geotailmagP200705.dat geotailmagP200705.dat] timeformat is <code>$Y $m $d $H $M $S</code> and starting at [http://vmo.igpp.ucla.edu/data1/Weygand/PropagatedSolarWindGSM/weimer/Geotail/mag/2007/geotailmagP200706.dat geotailmagP200706.dat] timeformat is <code>$d $m $Y $H $M $S</code>.  For this reason, <code>weimer/Geotail/mag</code> is going to be considered as two datasets.  In addition, instead of automatically determining the start/stop time of the datasets (so in case the directory content changes), I have hard-wired the stop time in DD1 and the start time in DD2 - the start time for DD1 will be determined by code inspecting the directory; same for the stop time for DD2.

SPASE Record claims (stop time is wrong; timeformat is wrong for most of the listed time span)

<pre>
<TemporalDescription>
	<TimeSpan>
		<StartDate>1992-09-01T00:00:00.000</StartDate>
		<StopDate>2010-07-31T23:59:00.000</StopDate>
	<Note>
		Time format in data files is: Day Month Year Hour Minute Second (DD MM YYYY HH MM SS.SSS)
	</Note>
	</TimeSpan>
</TemporalDescription>
</pre>

Also,
* My code found that the StartDate of the data set is <code>1993-10-01T04:00:00.000</code> whereas the SPASE record claims <code>1992-09-01T00:00:00.000</code>
* I found the above XML file by searching https://www.google.com/webhp?sourceid=chrome-instant&ion=1&espv=2&ie=UTF-8#safe=off&q=%22Weygand%2FPropagatedSolarWindGSM%2Fweimer%2FGeotail%2F%22+spase - it could be that a more correct version exists but is not indexed by Google.  This would be a Very Bad thing.  
* [http://vmo.igpp.ucla.edu/data1/Weygand/PropagatedSolarWindGSM/weimer/Geotail/mag/header4dat header4dat] has different variable names than that in the [http://vmo.nasa.gov/mission/metadata/VMO/NumericalData/Weygand/Geotail/MGF/Processed/GSM/PT60S.xml SPASE record]. I personally think it is important to allow a mapping from the the original data provider's variable naming to one used in SPASE.  I think it is a bit presumptuous for a SPASE author to decide to over-ride an author's original naming of a parameter without referenecing the fact that he did it.  I see this often in SPASE records where the SPASE author is different from the data set author.  Here, strangely, the data set author is the author of the SPASE record.

Based on inpection of SPASE records, I decided it would be easiest to 
* write code to generate the TSDSFE catalog than to write code to extract info from SPASE records;
* write additional code/metadata to supplement what is found in SPASE (and to write code to verify that that what is in SPASE record is consistent with that found in directories);
* I suspect that James is more diligent in updating the header4dat files than the SPASE records, so I'll defer to these READMEs as the authoritative source.
* In my the catalog-level metadata I'll have pointers to the URL to the definitive SPASE record and the header4dat files and the user will need to use combine the informaion as needed to learn about the dataset.

== 4. ==

I would query a (hypotetical) service 

 http://spase.org/?catalog=spase://VMO/NumericalData/Weygand/

and get a list of datasets under Weygand, such as

 spase://VMO/NumericalData/Weygand/ACE/TAP/Propagated.3DP/GSE/PT60S
 spase://VMO/NumericalData/Weygand/Wind/TAP/Propagated.3DP/GSE/PT60S
 spase://VMO/NumericalData/Weygand/Geotail/TAP/Propagated.LEP/GSE/PT60S.xml
 ...

and within each of the above SPASE records is a URI template.

I could use this SPASE service to do everything in 3. above.

= Discussion =

I think that there are the following core services

# TSDS + TSDSFE, which is a reference implementation - finalize software development over two years then go into "maintenance" mode.
# Autoplot maintenance of core parts used by TSDS/TSDSFE (file readers and servlet at minimum)
# Development and finalization of how to map to/from TSDS Catalog to SPASE.  Writing SPASE records that can be easily used by TSDSFE; writing code to autoupdate and autogenerate SPASE records.
# Development of way for organizing and communicating with all of the services that are connected to (sort of like how Jeremy has monthly meetings with CDAWeb group).  For example, if people started using Weygand dataset though TSDSFE, we would need coordination/communication with Todd.

Other activities
# ViViz - Could be a useful "Value Added" proposal.
# DD - development.  Would take about as much effort as URI Template specification.  Not sure how relevant this is for SPASE.  It is useful for TSDSFE and Autoplot, but I am not sure where else it would be used.

